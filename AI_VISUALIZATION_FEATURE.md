# AI Model Visualization Feature

**Date:** October 31, 2025  
**Status:** ğŸš§ IN PROGRESS  

---

## ğŸ¯ Feature Overview

Add visual previews to AI model nodes showing what the model detects with bounding boxes, labels, heatmaps, and other visualizations.

### Key Capabilities:
1. **Live Preview** - See annotated frames in real-time
2. **Multiple Viz Types** - Bounding boxes, heatmaps, pose skeletons, segmentation masks
3. **Output to Nodes** - Send annotated frames to Video Preview nodes
4. **Standard for All AI** - Apply to all AI models (YOLO, Pose, Segmentation, etc.)

---

## âœ… Completed

### 1. Backend Visualization Engine (`backend/workflows/visualization.py`)

**DetectionVisualizer Class:**
- âœ… `draw_detections()` - Bounding boxes with labels and confidence
- âœ… `draw_detection_count()` - Count overlay
- âœ… `draw_heatmap()` - Gaussian heatmap of detections
- âœ… `draw_zones()` - Detection zone polygons
- âœ… `create_thumbnail()` - Thumbnail generation
- âœ… `get_class_color()` - Consistent colors per class

**PoseVisualizer Class:**
- âœ… `draw_pose()` - Skeleton and keypoints for pose estimation

**SegmentationVisualizer Class:**
- âœ… `draw_masks()` - Instance segmentation masks with transparency

### 2. Video Preview Node (`workflow-builder/src/nodes/VideoPreviewNode.jsx`)

- âœ… Canvas-based frame display
- âœ… WebSocket connection for live frames
- âœ… Stats overlay (FPS, detections, latency)
- âœ… Connection detection
- âœ… Base64 image decoding

---

## ğŸš§ TODO

### Backend Integration

**1. Update Model Processing** (`backend/workflows/realtime_executor.py`)
```python
# Add to _process_through_model():
- Check if visualization enabled in model node data
- Create DetectionVisualizer instance
- Draw annotations on frame copy
- Encode to JPEG
- Convert to base64
- Send to Video Preview nodes via WebSocket
```

**2. WebSocket Frame Streaming**
```python
# Add method to send annotated frames:
async def _send_annotated_frame(node_id, frame, detections, stats):
    # Encode frame to JPEG
    # Convert to base64
    # Emit via WebSocket with type='annotated_frame'
```

**3. Handle Visualization Settings**
```python
# Read from model node data:
{
  "enableVisualization": true,
  "visualizationType": "boxes",  # boxes, heatmap, both
  "showConfidence": true,
  "showLabels": true,
  "minConfidence": 0.5
}
```

### Frontend Updates

**1. Update Model Node** (`workflow-builder/src/nodes/ModelNode.jsx`)

Add visualization settings panel:
```jsx
<div className="visualization-settings">
  <toggle> Enable Visualization </toggle>
  <select> Visualization Type </select>
  <checkbox> Show Confidence </checkbox>
  <checkbox> Show Labels </checkbox>
  <slider> Min Confidence </slider>
</div>
```

**2. Register Video Preview Node** (`workflow-builder/src/App.jsx`)
```javascript
import VideoPreviewNode from './nodes/VideoPreviewNode'

const nodeTypes = {
  // ... existing
  videoPreview: VideoPreviewNode,
}
```

**3. Add to Sidebar** (`workflow-builder/src/components/Sidebar.jsx`)
```javascript
debug: {
  items: [
    { type: 'videoPreview', label: 'Video Preview', icon: 'ğŸ“º', description: 'Live annotated video' },
    // ... existing
  ]
}
```

### Optimization

**1. Frame Rate Control**
- Only send visualization frames at specified FPS (default: 10 fps)
- Skip frames to reduce bandwidth

**2. JPEG Quality**
- Adjustable quality (50-95)
- Balance between quality and bandwidth

**3. Selective Streaming**
- Only send frames when Video Preview node connected
- Stop streaming when node disconnected

---

## ğŸ“‹ Implementation Steps

### Phase 1: Basic Visualization (CURRENT)
1. âœ… Create visualization utilities
2. âœ… Create Video Preview node
3. â³ Integrate into model processing
4. â³ Add WebSocket streaming
5. â³ Register nodes and update UI

### Phase 2: Advanced Features
6. â³ Add heatmap visualization
7. â³ Add pose skeleton rendering
8. â³ Add segmentation masks
9. â³ Add zone overlays
10. â³ Performance optimization

### Phase 3: Extended Support
11. â³ Apply to all AI models
12. â³ Add custom visualization options
13. â³ Export/save annotated frames
14. â³ Recording functionality

---

## ğŸ¨ Visualization Types

### 1. Bounding Boxes (Default)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ person 0.95â”‚ â† Label with confidence
â”‚            â”‚
â”‚     â–“â–“     â”‚
â”‚    â–“â–“â–“â–“    â”‚
â”‚     â–“â–“     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Heatmap
```
Gaussian blur overlays showing
detection density/concentration
```

### 3. Pose Skeleton
```
Keypoints connected with lines
showing body pose structure
```

### 4. Segmentation Masks
```
Colored semi-transparent overlays
showing exact object boundaries
```

---

## ğŸ”Œ Workflow Examples

### Example 1: Basic Detection Viz
```
Video Input â†’ YOLOv8N â†’ Video Preview
              (viz enabled)
```

### Example 2: Filtered Visualization
```
Video Input â†’ YOLOv8N â†’ Detection Filter â†’ Video Preview
              (viz ON)   (person only)
```

### Example 3: Multiple Outputs
```
Video Input â†’ YOLOv8N â”¬â†’ Video Preview (visualized)
              (viz ON) â”œâ†’ Debug Console (data)
                       â””â†’ Email Alert (action)
```

### Example 4: Pose Estimation
```
Video Input â†’ Pose Model â†’ Video Preview
              (skeleton ON)
```

---

## ğŸ’¾ Data Format

### Annotated Frame Message
```json
{
  "type": "annotated_frame",
  "node_id": "model-12345",
  "workflow_id": "workflow-67890",
  "frame_data": "base64_encoded_jpeg...",
  "fps": 10,
  "detections_count": 3,
  "processing_time_ms": 45,
  "timestamp": "2025-10-31T20:00:00Z",
  "visualization_type": "boxes",
  "resolution": {
    "width": 1920,
    "height": 1080
  }
}
```

---

## ğŸš€ Quick Start (When Complete)

1. **Add Video Preview Node**
   - Drag from Debug & Output section
   - Connect to AI model output

2. **Enable Visualization on Model**
   - Click âš™ï¸ on model node
   - Toggle "Enable Visualization"
   - Choose visualization type

3. **Run Workflow**
   - Click Execute
   - See live annotated frames in Video Preview

---

## ğŸ¯ Next Immediate Steps

1. Register Video Preview node in App.jsx and Sidebar.jsx
2. Add visualization toggle to Model node UI
3. Integrate DetectionVisualizer into backend model processing
4. Add WebSocket streaming for annotated frames
5. Test with simple workflow: Video â†’ YOLO â†’ Video Preview

---

## ğŸ› Testing Checklist

- [ ] Video Preview node appears in sidebar
- [ ] Can drag Video Preview onto canvas
- [ ] Connects to model nodes
- [ ] Model node has visualization toggle
- [ ] Annotated frames display in preview
- [ ] Bounding boxes draw correctly
- [ ] Labels and confidence show
- [ ] FPS counter works
- [ ] Frame updates in real-time
- [ ] Works with detection filters
- [ ] Multiple preview nodes supported
- [ ] Disconnecting stops streaming

---

## ğŸ“ Notes

- Visualization is optional and disabled by default
- Only active when Video Preview node connected
- Uses JPEG compression to reduce bandwidth
- Color coding consistent per object class
- Track IDs shown when available
- Supports all YOLO models (detection, pose, segmentation)

---

**Status:** Ready for Phase 1 completion - Need to integrate backend and register nodes.

